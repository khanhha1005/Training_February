{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/trancatkhanh/Downloads/GAME\n"
     ]
    }
   ],
   "source": [
    "%cd /Users/trancatkhanh/Downloads/GAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from base.MachiKoro.env import *\n",
    "#0 Array bias trong mỗi trận\n",
    "#1 Array bias sau 100k trận \n",
    "#2 Lưu số trận \n",
    "#3 lưu hệ số đã dùng \n",
    "#4 Tỷ lệ thắng khi đấu 10k trận \n",
    "#5 Trigger để train 100k trận \n",
    "#6 Đếm số lần yếu liên tiếp\n",
    "#7 Lưu array cho policy yếu \n",
    "#8 State của trận đấu\n",
    "#9 Action của trận đấu\n",
    "#10 Reward của trận đấu\n",
    "#11 Số trận lưu state\n",
    "#12 Trigger policy yếu\n",
    "\n",
    "perx = [np.array([np.random.rand(getActionSize()) for _ in range(1)]),np.zeros((1,getActionSize())),np.zeros((1,1)),np.array([np.random.rand(getActionSize()) for _ in range(1)]),np.zeros((1,2)),np.zeros((1,2)),np.zeros((1,1)),np.array([np.random.rand(getActionSize()) for _ in range(1)]),np.zeros((200000,getStateSize())),np.zeros((200000,1)),np.zeros((200000,1)),np.zeros((1,1)),np.zeros((1,2))]\n",
    "                         #0                                                      #1                   #2              #3                                                            #4              #5               #6                #7                                                               #8                                   #9               #10                       #11           #12"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Các hàm check tính chất của state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "@njit\n",
    "def check_min(state, reward):\n",
    "    just = np.zeros((200000,2))\n",
    "    for i in range(len(reward)):\n",
    "        if reward[i] == -1:\n",
    "            for j in range(i,len(reward)):\n",
    "                if reward[j] != -1:\n",
    "                    reward[i] = reward[j]\n",
    "                    break\n",
    "    # replace -1 with 0\n",
    "    for i in range(len(reward)):\n",
    "        if reward[i] == -1:\n",
    "            reward[i] = 0\n",
    "    # np.mean each array in the state and the corresponding reward\n",
    "    for i in range(len(reward)):\n",
    "        just[i][0] = np.mean(state[i])\n",
    "        just[i][1] = (reward[i][0])\n",
    "    # count the number of times each value of the state appears and the reward of each value of the state\n",
    "    count = np.zeros((200000,3))\n",
    "    for i in range(len(reward)):\n",
    "        for j in range(len(count)):\n",
    "            if just[i][0] == count[j][0]:\n",
    "                count[j][1] += 1\n",
    "                count[j][2] += just[i][1]\n",
    "                break\n",
    "            if count[j][0] == 0:\n",
    "                count[j][0] = just[i][0]\n",
    "                count[j][1] += 1\n",
    "                count[j][2] += just[i][1]\n",
    "                break\n",
    "    # find the value the lowest average reward\n",
    "    min = 0\n",
    "    index = 0\n",
    "    for i in range(len(count)):\n",
    "        if count[i][2] != 0:\n",
    "            min = count[i][2]/count[i][1]\n",
    "            index = i\n",
    "            break\n",
    "    return count[index][0]\n",
    "@njit\n",
    "def check_weaker(min,x):\n",
    "    if x == min:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent Hoàn Chỉnh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit()\n",
    "def p_bias(state,per):\n",
    "    # Chuyển Mode gồm 3 mode mode 0 - train bias , mode 1 - test bias , mode 2 - train policy yếu ,mode 3 - test policy yếu,mode 4 - lưu state\n",
    "    if per[4][0][0] > per[5][0][1] and per[4][0][1] == 10000 and per[5][0][0] == 1:\n",
    "      per[3][0] = np.copy(per[1][0]/np.max(per[1][0]))\n",
    "      # Lưu lại kết quả thắng\n",
    "      per[5][0][1] = 0 \n",
    "      per[5][0][1] += (per[4][0][0])\n",
    "      # Rest số trận thắng và số trận đấu \n",
    "      per[4][0][0] = 0\n",
    "      per[4][0][1] = 0 \n",
    "      # Chuyển sang train bias\n",
    "      per[5][0][0] = 0 \n",
    "      per[2][0][0] = 0\n",
    "      per[1][0] = np.zeros((1,getActionSize()))\n",
    "      # Reset số lần yếu liên tiếp\n",
    "      per[6][0][0] = 0 \n",
    "    elif per[5][0][1] > per[4][0][0] and per[4][0][1] == 10000 and per[5][0][0] == 1:\n",
    "      per[6][0][0] +=1 \n",
    "      # Chuyển sang train bias\n",
    "      per[5][0][0] = 0 \n",
    "      per[2][0][0] = 0\n",
    "      per[1][0] = np.zeros((1,getActionSize()))\n",
    "      # Rest số trận thắng và số trận đấu \n",
    "      per[4][0][0] = 0\n",
    "      per[4][0][1] = 0 \n",
    "\n",
    "    # Bắt đầu mode lưu state\n",
    "    if per[6][0][0] == 3 and per[11][0][0] < 200000 :\n",
    "      # Chuyển sang lưu state \n",
    "      per[5][0][0] = 4\n",
    "      per[2][0][0] = 0\n",
    "      # Rest số trận thắng và số trận đấu \n",
    "      per[4][0][1] = 0 \n",
    "      per[4][0][0] = 0\n",
    "      \n",
    "    # Hết mode lưu state chuyển sang train policy yếu\n",
    "    if per[5][0][0] == 4 and per[11][0][0] == 200000:\n",
    "      per[5][0][0] = 2\n",
    "\n",
    "    # Bất đầu mode train và test policy yếu hơn\n",
    "    if per[11][0][0] == 200000:\n",
    "      if per[4][0][0] > per[5][0][1] and per[4][0][1] == 10000 and per[5][0][0] == 3:\n",
    "        per[7][0] = np.copy(per[1][0]/np.max(per[1][0]))\n",
    "        # Lưu lại kết quả thắng\n",
    "        per[5][0][1] = 0 \n",
    "        per[5][0][1] += (per[4][0][0])\n",
    "        # Rest số trận thắng và số trận đấu \n",
    "        per[4][0][0] = 0\n",
    "        per[4][0][1] = 0 \n",
    "        # Chuyển sang train\n",
    "        per[5][0][0] = 2 \n",
    "        per[2][0][0] = 0\n",
    "        per[1][0] = np.zeros((1,getActionSize()))\n",
    "\n",
    "      elif per[5][0][1] > per[4][0][0] and per[4][0][1] == 10000 and per[5][0][0] == 3:\n",
    "        # Chuyển sang train\n",
    "        per[5][0][0] = 2 \n",
    "        per[2][0][0] = 0\n",
    "        per[1][0] = np.zeros((1,getActionSize()))\n",
    "        # Rest số trận thắng và số trận đấu \n",
    "        per[4][0][0] = 0\n",
    "        per[4][0][1] = 0 \n",
    "      \n",
    "    # reset per[1][0] sau 100k trận\n",
    "    if int(per[2][0][0]) == 100000 and per[11][0][0] < 200000:\n",
    "      per[3][0] = np.copy(per[1][0]/np.max(per[1][0]))\n",
    "      per[2][0][0] = 0\n",
    "      per[5][0][0] = 1\n",
    "    # reset per[1][0] sau 10k trận\n",
    "    if int(per[2][0][0]) == 100000 and per[11][0][0] == 200000:\n",
    "      per[7][0] = np.copy(per[1][0]/np.max(per[1][0]))\n",
    "      per[2][0][0] = 0\n",
    "      per[5][0][0] = 3\n",
    "      \n",
    "    if per[11][0][0] == 200000 and per[12][0][0] == 0:\n",
    "      per[12][0][0] += check_min(per[8], per[10])\n",
    "\n",
    "    # Chế độ train bias\n",
    "    if int(per[2][0][0]) < 100000 and per[5][0][0] == 0  :\n",
    "      actions = getValidActions(state)\n",
    "      actions *= per[0][0]\n",
    "      action = np.argmax(actions)\n",
    "      if getReward(state) == 1 :\n",
    "          per[1] += per[0][0]\n",
    "      if getReward(state) == 0:\n",
    "          per[0][0] = np.random.rand(getActionSize())\n",
    "\n",
    "    # Chế độ test bias\n",
    "    elif int(per[2][0][0]) <10000  and per[5][0][0] == 1 : \n",
    "      list_action2 = getValidActions(state)\n",
    "      action = np.argmax(list_action2*per[3][0])    \n",
    "      if getReward(state) == 1:\n",
    "        per[4][0][0]+=1\n",
    "      if getReward(state) != -1:\n",
    "        per[4][0][1]+=1  \n",
    "\n",
    "    # Chế độ train policy yếu\n",
    "    elif int(per[2][0][0]) < 100000 and per[5][0][0] == 2 and per[11][0][0] == 200000 :\n",
    "      actions = getValidActions(state)\n",
    "      # Check xem policy có yếu không \n",
    "      Check_yeu = check_weaker(per[12][0][0],np.mean(state))\n",
    "      if Check_yeu == 1:\n",
    "        per[12][0][1] = Check_yeu\n",
    "        actions *= per[0][0]\n",
    "        action = np.argmax(actions)\n",
    "      else:\n",
    "        actions *= per[3][0]\n",
    "        action = np.argmax(actions)\n",
    "      if getReward(state) == 1 and per[12][0][1] == 1:\n",
    "        per[1] += per[0][0]\n",
    "        per[12][0][1] = 0 \n",
    "      if getReward(state) == 0 and per[12][0][1] == 1:\n",
    "        per[0][0] = np.random.rand(getActionSize())\n",
    "        per[12][0][1] = 0 \n",
    "\n",
    "    # chế độ test policy yếu\n",
    "    elif int(per[2][0][0]) <10000 and  per[5][0][0] == 3 and per[11][0][0] == 200000:\n",
    "      actions = getValidActions(state)\n",
    "      # Check xem policy có yếu không \n",
    "      if check_weaker(per[12][0][0],np.mean(state)) == 1:\n",
    "        actions *= per[7][0]\n",
    "        action = np.argmax(actions)\n",
    "      else:\n",
    "        actions *= per[3][0]\n",
    "        action = np.argmax(actions)\n",
    "      if getReward(state) == 1:\n",
    "        per[4][0][0]+=1\n",
    "      if getReward(state) != -1:\n",
    "        per[4][0][1]+=1  \n",
    "    \n",
    "\n",
    "    # Báo chuyển sang chế độ lưu state và action\n",
    "    if per[5][0][0] == 4 and per[11][0][0] < 200000:\n",
    "      list_action2 = getValidActions(state)\n",
    "      action = np.argmax(list_action2*per[3][0]) \n",
    "\n",
    "\n",
    "    # Lưu state và action\n",
    "    if getReward(state) != -2 and per[11][0][0] < 200000 and per[5][0][0] == 4:\n",
    "        for i in range(getStateSize()):\n",
    "          per[8][int(per[11][0][0])][i] += state[i]        \n",
    "        per[9][int(per[11][0][0])][0] += int(action)\n",
    "        per[10][int(per[11][0][0])][0] += int(getReward(state))\n",
    "        per[11][0][0] += 1\n",
    "\n",
    "    # đếm số ván đấu \n",
    "    if getReward(state) != -1 :\n",
    "        per[2][0][0] += 1\n",
    "    return action,per\n",
    "\n",
    "win, bias = numba_main_2(p_bias, 200000,perx,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.54685488, 0.07957582, 0.32035392, 0.39445544, 0.13045458,\n",
       "         0.99316945, 0.96677797, 0.13765538, 0.85117141, 0.64607006,\n",
       "         0.08449115, 0.66525764, 0.1093372 , 0.37422485, 0.9482102 ,\n",
       "         0.31147577, 0.59184928, 0.24460566, 0.30285188, 0.96978224,\n",
       "         0.08517401, 0.50117706, 0.50867757, 0.52192646, 0.72301157,\n",
       "         0.79196159, 0.01174375, 0.38781934, 0.68647596, 0.1825646 ,\n",
       "         0.82072735, 0.96151887, 0.95726548, 0.22223554, 0.97075484,\n",
       "         0.02579015, 0.96471094, 0.52428511, 0.17683278, 0.37222494,\n",
       "         0.97551717, 0.68478236, 0.45416076, 0.78166987, 0.80443589,\n",
       "         0.31804263, 0.7540271 , 0.88886953, 0.66735828, 0.18476232,\n",
       "         0.52974775, 0.07054105, 0.24150966, 0.80266307]]),\n",
       " array([[1811.99135598, 1919.22588837, 1817.98833776, 1821.04163887,\n",
       "         1781.72378926, 1930.56125748, 1823.67900211, 1878.79230887,\n",
       "         1839.71195819, 1807.01991514, 1838.15911319, 1996.42744254,\n",
       "         1755.00417909, 1852.91859418, 1897.43571003, 1931.16428506,\n",
       "         1802.65867088, 1905.12833908, 1856.30687281, 1785.98498588,\n",
       "         1914.21755141, 1857.25128445, 1878.75023573, 1814.04660131,\n",
       "         1847.37962087, 1900.43858078, 1866.27691666, 1823.59402224,\n",
       "         1794.43088847, 1963.89339818, 1847.7625128 , 1800.1102885 ,\n",
       "         1763.19036564, 1909.757425  , 1874.04964979, 1882.18377534,\n",
       "         1921.29873492, 1810.1647911 , 1834.77354388, 1778.05087775,\n",
       "         1927.21313898, 1920.97804772, 1900.88430645, 1787.43586528,\n",
       "         1832.08748132, 1847.85602485, 1801.26032629, 1905.2205269 ,\n",
       "         1866.51233181, 1854.77555362, 1806.42283376, 1766.23746132,\n",
       "         1751.19382487, 1903.81682628]]),\n",
       " array([[9505.]]),\n",
       " array([[0.76800219, 0.75458793, 0.86169755, 0.78648125, 0.7796641 ,\n",
       "         0.79517286, 0.79500905, 0.72131575, 0.72502295, 0.73666026,\n",
       "         0.76421592, 0.78986415, 0.79136551, 0.82395645, 0.79486734,\n",
       "         0.72562816, 0.79700345, 0.841034  , 0.83531845, 0.79073421,\n",
       "         0.73676355, 0.77396329, 0.73298772, 0.7380255 , 0.82164946,\n",
       "         0.75793694, 0.75560515, 0.85205814, 0.75911022, 0.76490029,\n",
       "         0.78443819, 0.8343276 , 0.80174596, 0.77822587, 0.92216061,\n",
       "         1.        , 0.76842666, 0.71933025, 0.85758074, 0.88533004,\n",
       "         0.63357837, 0.76811233, 0.74881459, 0.68800238, 0.75975614,\n",
       "         0.70556378, 0.79844757, 0.76495854, 0.75469185, 0.91923885,\n",
       "         0.88878279, 0.93446799, 0.90659646, 0.2814299 ]]),\n",
       " array([[0., 0.]]),\n",
       " array([[  2., 859.]]),\n",
       " array([[3.]]),\n",
       " array([[0.91331186, 0.93222957, 0.95635929, 1.        , 0.94646338,\n",
       "         0.95820354, 0.9255042 , 0.93314554, 0.9884848 , 0.91249096,\n",
       "         0.9286949 , 0.97462857, 0.97996802, 0.9526814 , 0.95102426,\n",
       "         0.93388054, 0.92080078, 0.9344423 , 0.92694492, 0.9773318 ,\n",
       "         0.89910019, 0.99553393, 0.93960282, 0.99376143, 0.94589831,\n",
       "         0.9810653 , 0.92488355, 0.90340644, 0.90699749, 0.97561652,\n",
       "         0.94162445, 0.92452678, 0.96029059, 0.91615043, 0.94052842,\n",
       "         0.92071711, 0.94866422, 0.96269562, 0.94211914, 0.95654585,\n",
       "         0.91918746, 0.93462977, 0.89101336, 0.94416609, 0.96558002,\n",
       "         0.94704906, 0.89891279, 0.96125609, 0.98297981, 0.93973701,\n",
       "         0.938517  , 0.87726232, 0.93719964, 0.94826302]]),\n",
       " array([[0., 1., 0., ..., 0., 1., 1.],\n",
       "        [1., 1., 0., ..., 0., 1., 7.],\n",
       "        [2., 1., 1., ..., 0., 1., 1.],\n",
       "        ...,\n",
       "        [1., 1., 1., ..., 0., 0., 7.],\n",
       "        [1., 1., 2., ..., 0., 0., 1.],\n",
       "        [1., 1., 2., ..., 0., 0., 7.]]),\n",
       " array([[ 1.],\n",
       "        [35.],\n",
       "        [ 1.],\n",
       "        ...,\n",
       "        [35.],\n",
       "        [ 1.],\n",
       "        [35.]]),\n",
       " array([[1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        ...,\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]]),\n",
       " array([[200000.]]),\n",
       " array([[0.80555556, 0.        ]])]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perx"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test lại tỷ lệ thắng của level 1 game MachiKoro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "271\n"
     ]
    }
   ],
   "source": [
    "@njit()\n",
    "def p_bias_1(state,per):\n",
    "    actions = getValidActions(state)\n",
    "    # Check xem policy có yếu không \n",
    "    if check_weaker(per[12][0][0],np.mean(state)) == 1:\n",
    "      actions *= per[7][0]\n",
    "      action = np.argmax(actions)\n",
    "    else:\n",
    "      actions *= per[3][0]\n",
    "      action = np.argmax(actions)\n",
    "    return action,per\n",
    "win, bias = numba_main_2(p_bias_1, 1000,perx,1)\n",
    "print(win)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find the most important value of index in the state that when it appear the policy dont work well\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_most_importane_feature(perx):\n",
    "    import pandas as pd\n",
    "\n",
    "    df = pd.DataFrame(perx[8])\n",
    "    df['action'] = perx[9]\n",
    "    df['reward'] = perx[10]\n",
    "    for i in range(len(df)):\n",
    "        if df['reward'][i] == -1:\n",
    "            for j in range(i,len(df)):\n",
    "                if df['reward'][j] != -1:\n",
    "                    df['reward'][i] = df['reward'][j]\n",
    "                    break\n",
    "    df = df[df['reward'] != -1]\n",
    "\n",
    "    import pandas as pd\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "    # Load the state-action dataset\n",
    "\n",
    "    # Split the data into features (state properties) and target (outcome)\n",
    "    features = df.drop(\"reward\", axis=1)\n",
    "    target = df[\"reward\"]\n",
    "\n",
    "    # Train a Random Forest Classifier on the data\n",
    "    clf = RandomForestClassifier()\n",
    "    clf.fit(features, target)\n",
    "\n",
    "    # Get the feature importances\n",
    "    importances = clf.feature_importances_\n",
    "\n",
    "    # Find the property (x) of the state that is most important for the policy's performance\n",
    "    x = features.columns[importances.argmax()]\n",
    "    # Plot the top  feature importances \n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.title(\"Feature importances\")\n",
    "    plt.bar(range(features.shape[1]), importances[indices], color=\"r\", align=\"center\")\n",
    "    plt.xticks(range(features.shape[1]), features.columns[indices], rotation=90)\n",
    "    plt.xlim([-1, features.shape[1]])\n",
    "    plt.show()\n",
    "    most_imp_feature = None\n",
    "    lowest_percentage = 100\n",
    "    print('feature importances',x)\n",
    "    for i in df[x].unique():\n",
    "        current_percentage = df[df[x] == i]['reward'].value_counts()[1]/df[df[x] == i]['reward'].value_counts().sum()\n",
    "        if current_percentage < lowest_percentage:\n",
    "            most_imp_feature = i\n",
    "            lowest_percentage = current_percentage\n",
    "\n",
    "    print(\"The value of the most important feature with the lowest percentage of value 1 in reward is:\", most_imp_feature)#  all the below code in one function    \n",
    "    return most_imp_feature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0 +10\n",
    "d = 0 \n",
    "while 0<i:\n",
    "    i = i-1\n",
    "    d= d+1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ff2136a0fe6bc790f1b40d257e6b1bba23119827483ea2b7c12c8cc23c661a47"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
