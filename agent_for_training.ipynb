{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/trancatkhanh/Downloads/GAME\n"
     ]
    }
   ],
   "source": [
    "%cd /Users/trancatkhanh/Downloads/GAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from base.MachiKoro.env import *\n",
    "#0 Array bias trong mỗi trận\n",
    "#1 Array bias sau 100k trận \n",
    "#2 Lưu số trận \n",
    "#3 lưu hệ số đã dùng \n",
    "#4 Tỷ lệ thắng khi đấu 10k trận \n",
    "#5 Trigger để train 100k trận \n",
    "#6 Đếm số lần yếu liên tiếp\n",
    "#7 Lưu array cho policy yếu \n",
    "#8 State của trận đấu\n",
    "#9 Action của trận đấu\n",
    "#10 Reward của trận đấu\n",
    "#11 Số trận lưu state\n",
    "#12 Trigger policy yếu\n",
    "\n",
    "perx = [np.array([np.random.rand(getActionSize()) for _ in range(1)]),np.zeros((1,getActionSize())),np.zeros((1,1)),np.array([np.random.rand(getActionSize()) for _ in range(1)]),np.zeros((1,2)),np.zeros((1,2)),np.zeros((1,1)),np.array([np.random.rand(getActionSize()) for _ in range(1)]),np.zeros((200000,getStateSize())),np.zeros((200000,1)),np.zeros((200000,1)),np.zeros((1,1)),np.zeros((1,2))]\n",
    "                         #0                                                      #1                   #2              #3                                                            #4              #5               #6                #7                                                               #8                                   #9               #10                       #11           #12"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Các hàm check tính chất của state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "@njit\n",
    "def check_min(state, reward):\n",
    "    just = np.zeros((200000,2))\n",
    "    for i in range(len(reward)):\n",
    "        if reward[i] == -1:\n",
    "            for j in range(i,len(reward)):\n",
    "                if reward[j] != -1:\n",
    "                    reward[i] = reward[j]\n",
    "                    break\n",
    "    # replace -1 with 0\n",
    "    for i in range(len(reward)):\n",
    "        if reward[i] == -1:\n",
    "            reward[i] = 0\n",
    "    # np.mean each array in the state and the corresponding reward\n",
    "    for i in range(len(reward)):\n",
    "        just[i][0] = np.mean(state[i])\n",
    "        just[i][1] = (reward[i][0])\n",
    "    # count the number of times each value of the state appears and the reward of each value of the state\n",
    "    count = np.zeros((200000,3))\n",
    "    for i in range(len(reward)):\n",
    "        for j in range(len(count)):\n",
    "            if just[i][0] == count[j][0]:\n",
    "                count[j][1] += 1\n",
    "                count[j][2] += just[i][1]\n",
    "                break\n",
    "            if count[j][0] == 0:\n",
    "                count[j][0] = just[i][0]\n",
    "                count[j][1] += 1\n",
    "                count[j][2] += just[i][1]\n",
    "                break\n",
    "    # find the value the lowest average reward\n",
    "    min = 0\n",
    "    index = 0\n",
    "    for i in range(len(count)):\n",
    "        if count[i][2] != 0:\n",
    "            min = count[i][2]/count[i][1]\n",
    "            index = i\n",
    "            break\n",
    "    return count[index][0]\n",
    "@njit\n",
    "def check_weaker(min,x):\n",
    "    if x == min:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent Hoàn Chỉnh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "bot dua ra action khong hop le",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/ds/4lcv95w11y7brm6dqhc04s240000gn/T/ipykernel_19753/939229735.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m \u001b[0mwin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumba_main_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_bias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mperx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Downloads/GAME/base/MachiKoro/env.py\u001b[0m in \u001b[0;36mnumba_main_2\u001b[0;34m(p0, n_game, per_player, level)\u001b[0m\n\u001b[1;32m    877\u001b[0m     \u001b[0mper10\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    878\u001b[0m     \u001b[0mper11\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 879\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mn_game_numba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_game\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mper_player\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mper0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mper1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mper2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mper3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mper4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mper5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mper6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mper7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mper8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mper9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mper10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mper11\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    880\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/GAME/base/MachiKoro/env.py\u001b[0m in \u001b[0;36mone_game_numba\u001b[0;34m()\u001b[0m\n\u001b[1;32m    827\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    828\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgetValidActions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplayer_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 829\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bot dua ra action khong hop le'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m         \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstepEnv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_card_fee\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: bot dua ra action khong hop le"
     ]
    }
   ],
   "source": [
    "@njit()\n",
    "def p_bias(state,per):\n",
    "    # Chuyển Mode gồm 3 mode mode 0 - train bias , mode 1 - test bias , mode 2 - train policy yếu ,mode 3 - test policy yếu,mode 4 - lưu state\n",
    "    if per[4][0][0] > per[5][0][1] and per[4][0][1] == 1000 and per[5][0][0] == 1:\n",
    "      per[3][0] = np.copy(per[1][0]/np.max(per[1][0]))\n",
    "      # Lưu lại kết quả thắng\n",
    "      per[5][0][1] = 0 \n",
    "      per[5][0][1] += (per[4][0][0])\n",
    "      # Rest số trận thắng và số trận đấu \n",
    "      per[4][0][0] = 0\n",
    "      per[4][0][1] = 0 \n",
    "      # Chuyển sang train bias\n",
    "      per[5][0][0] = 0 \n",
    "      per[2][0][0] = 0\n",
    "      per[1][0] = np.zeros((1,getActionSize()))\n",
    "      # Reset số lần yếu liên tiếp\n",
    "      per[6][0][0] = 0 \n",
    "    elif per[5][0][1] > per[4][0][0] and per[4][0][1] == 1000 and per[5][0][0] == 1:\n",
    "      per[6][0][0] +=1 \n",
    "      # Chuyển sang train bias\n",
    "      per[5][0][0] = 0 \n",
    "      per[2][0][0] = 0\n",
    "      per[1][0] = np.zeros((1,getActionSize()))\n",
    "      # Rest số trận thắng và số trận đấu \n",
    "      per[4][0][0] = 0\n",
    "      per[4][0][1] = 0 \n",
    "\n",
    "    # Bắt đầu mode lưu state\n",
    "    if per[6][0][0] == 3 and per[11][0][0] < 200000 :\n",
    "      # Chuyển sang lưu state \n",
    "      per[5][0][0] = 4\n",
    "      per[2][0][0] = 0\n",
    "      # Rest số trận thắng và số trận đấu \n",
    "      per[4][0][1] = 0 \n",
    "      per[4][0][0] = 0\n",
    "      \n",
    "    # Hết mode lưu state chuyển sang train policy yếu\n",
    "    if per[5][0][0] == 4 and per[11][0][0] == 200000:\n",
    "      per[5][0][0] = 2\n",
    "\n",
    "    # Bất đầu mode train và test policy yếu hơn\n",
    "    if per[11][0][0] == 200000:\n",
    "      if per[4][0][0] > per[5][0][1] and per[4][0][1] == 1000 and per[5][0][0] == 3:\n",
    "        per[7][0] = np.copy(per[1][0]/np.max(per[1][0]))\n",
    "        # Lưu lại kết quả thắng\n",
    "        per[5][0][1] = 0 \n",
    "        per[5][0][1] += (per[4][0][0])\n",
    "        # Rest số trận thắng và số trận đấu \n",
    "        per[4][0][0] = 0\n",
    "        per[4][0][1] = 0 \n",
    "        # Chuyển sang train\n",
    "        per[5][0][0] = 2 \n",
    "        per[2][0][0] = 0\n",
    "        per[1][0] = np.zeros((1,getActionSize()))\n",
    "\n",
    "      elif per[5][0][1] > per[4][0][0] and per[4][0][1] == 1000 and per[5][0][0] == 3:\n",
    "        # Chuyển sang train\n",
    "        per[5][0][0] = 2 \n",
    "        per[2][0][0] = 0\n",
    "        per[1][0] = np.zeros((1,getActionSize()))\n",
    "        # Rest số trận thắng và số trận đấu \n",
    "        per[4][0][0] = 0\n",
    "        per[4][0][1] = 0 \n",
    "      \n",
    "    # reset per[1][0] sau 10k trận\n",
    "    if int(per[2][0][0]) == 10000 and per[11][0][0] < 200000:\n",
    "      per[3][0] = np.copy(per[1][0]/np.max(per[1][0]))\n",
    "      per[2][0][0] = 0\n",
    "      per[5][0][0] = 1\n",
    "    # reset per[1][0] sau 10k trận\n",
    "    if int(per[2][0][0]) == 10000 and per[11][0][0] == 200000:\n",
    "      per[7][0] = np.copy(per[1][0]/np.max(per[1][0]))\n",
    "      per[2][0][0] = 0\n",
    "      per[5][0][0] = 3\n",
    "      \n",
    "    if per[11][0][0] == 200000 and per[12][0][0] == 0:\n",
    "      per[12][0][0] += check_min(per[8], per[10])\n",
    "\n",
    "    # Chế độ train bias\n",
    "    if int(per[2][0][0]) < 10000 and per[5][0][0] == 0  :\n",
    "      actions = getValidActions(state)\n",
    "      actions *= per[0][0]\n",
    "      action = np.argmax(actions)\n",
    "      if getReward(state) == 1 :\n",
    "          per[1] += per[0][0]\n",
    "      if getReward(state) == 0:\n",
    "          per[0][0] = np.random.rand(getActionSize())\n",
    "\n",
    "    # Chế độ test bias\n",
    "    elif int(per[2][0][0]) <1000  and per[5][0][0] == 1 : \n",
    "      list_action2 = getValidActions(state)\n",
    "      action = np.argmax(list_action2*per[3][0])    \n",
    "      if getReward(state) == 1:\n",
    "        per[4][0][0]+=1\n",
    "      if getReward(state) != -1:\n",
    "        per[4][0][1]+=1  \n",
    "\n",
    "    # Chế độ train policy yếu\n",
    "    elif int(per[2][0][0]) < 10000 and per[5][0][0] == 2 and per[11][0][0] == 200000 :\n",
    "      actions = getValidActions(state)\n",
    "      # Check xem policy có yếu không \n",
    "      Check_yeu = check_weaker(per[12][0][0],np.mean(state))\n",
    "      if Check_yeu == 1:\n",
    "        per[12][0][1] = Check_yeu\n",
    "        actions *= per[0][0]\n",
    "        action = np.argmax(actions)\n",
    "      else:\n",
    "        actions *= per[3][0]\n",
    "        action = np.argmax(actions)\n",
    "      if getReward(state) == 1 and per[12][0][1] == 1:\n",
    "        per[1] += per[0][0]\n",
    "        per[12][0][1] = 0 \n",
    "      if getReward(state) == 0 and per[12][0][1] == 1:\n",
    "        per[0][0] = np.random.rand(getActionSize())\n",
    "        per[12][0][1] = 0 \n",
    "\n",
    "    # chế độ test policy yếu\n",
    "    elif int(per[2][0][0]) <1000 and  per[5][0][0] == 3 and per[11][0][0] == 200000:\n",
    "      actions = getValidActions(state)\n",
    "      # Check xem policy có yếu không \n",
    "      if check_weaker(per[12][0][0],np.mean(state)) == 1:\n",
    "        actions *= per[7][0]\n",
    "        action = np.argmax(actions)\n",
    "      else:\n",
    "        actions *= per[3][0]\n",
    "        action = np.argmax(actions)\n",
    "      if getReward(state) == 1:\n",
    "        per[4][0][0]+=1\n",
    "      if getReward(state) != -1:\n",
    "        per[4][0][1]+=1  \n",
    "    \n",
    "\n",
    "    # Báo chuyển sang chế độ lưu state và action\n",
    "    if per[5][0][0] == 4 and per[11][0][0] < 200000:\n",
    "      list_action2 = getValidActions(state)\n",
    "      action = np.argmax(list_action2*per[3][0]) \n",
    "\n",
    "\n",
    "    # Lưu state và action\n",
    "    if getReward(state) != -2 and per[11][0][0] < 200000 and per[5][0][0] == 4:\n",
    "        for i in range(getStateSize()):\n",
    "          per[8][int(per[11][0][0])][i] += state[i]        \n",
    "        per[9][int(per[11][0][0])][0] += int(action)\n",
    "        per[10][int(per[11][0][0])][0] += int(getReward(state))\n",
    "        per[11][0][0] += 1\n",
    "\n",
    "    # đếm số ván đấu \n",
    "    if getReward(state) != -1 :\n",
    "        per[2][0][0] += 1\n",
    "    return action,per\n",
    "\n",
    "win, bias = numba_main_2(p_bias, 200000,perx,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.10519483, 0.66184734, 0.12742971, 0.83470961, 0.00454187,\n",
       "         0.45419722, 0.95757955, 0.77309958, 0.60884098, 0.58541094,\n",
       "         0.77947856, 0.57412287, 0.72778555, 0.0886228 , 0.87920988,\n",
       "         0.05591994, 0.47543379, 0.55463818, 0.27357237, 0.1501728 ,\n",
       "         0.38774188, 0.5852164 , 0.6152384 , 0.60622774, 0.66231281,\n",
       "         0.16144969, 0.86481721, 0.14600187, 0.44517251, 0.96016831,\n",
       "         0.03930424, 0.86999054, 0.81464495, 0.92986444, 0.33786883,\n",
       "         0.36895098, 0.34891099, 0.04818481, 0.82296613, 0.85438353,\n",
       "         0.19001965, 0.43080378, 0.99198919, 0.73565581, 0.90465215,\n",
       "         0.1001409 , 0.71911491, 0.78486635, 0.21275042, 0.6961762 ,\n",
       "         0.56029809, 0.61384006, 0.34876997, 0.6677653 ]]),\n",
       " array([[1103.60722336, 1166.35967085, 1048.07492629, 1134.36760212,\n",
       "         1099.1844981 ,  984.2566222 , 1094.77618407, 1050.04531244,\n",
       "         1118.69161696, 1182.43667395, 1086.6162719 ,  986.94793555,\n",
       "         1213.27559746, 1167.09095042, 1110.59751941, 1099.27429331,\n",
       "         1136.66677793, 1130.18302985, 1152.78541952, 1124.15677188,\n",
       "         1079.97104892, 1112.58787242, 1135.52205181, 1092.12834802,\n",
       "         1092.92692296, 1115.06993219, 1114.29580229, 1103.50727385,\n",
       "         1145.51235346, 1254.43937443, 1090.6096668 , 1132.29303451,\n",
       "         1075.49183886,  986.70721946, 1109.13846511, 1179.35573359,\n",
       "         1169.20100298, 1254.03575792, 1191.64543653, 1184.58942466,\n",
       "         1088.9675123 , 1036.39975123, 1119.41604287, 1209.51880864,\n",
       "         1092.41475872, 1230.45275228, 1100.11965889, 1089.92714452,\n",
       "         1193.05004247, 1205.7518979 , 1106.77362147, 1124.33891714,\n",
       "         1078.23455674, 1161.55630451]]),\n",
       " array([[1000.]]),\n",
       " array([[0.83025055, 0.74860717, 0.79398777, 0.76041707, 0.80312228,\n",
       "         0.79331829, 0.78742938, 0.77418303, 0.8011157 , 0.77498846,\n",
       "         0.79932567, 0.75529787, 0.76651086, 0.74431374, 0.74885484,\n",
       "         0.77738865, 0.76001383, 0.77544329, 0.74684376, 0.77877041,\n",
       "         0.78737198, 0.73418001, 0.74313342, 0.748448  , 0.77564016,\n",
       "         0.73039557, 0.7978379 , 0.78455588, 0.75657362, 0.79406548,\n",
       "         0.76543292, 0.76294113, 0.7798412 , 0.76306443, 0.9311548 ,\n",
       "         1.        , 0.77115014, 0.7741025 , 0.82753291, 0.89609033,\n",
       "         0.70319917, 0.70322435, 0.74520565, 0.70688803, 0.73324013,\n",
       "         0.68535119, 0.7862644 , 0.75763747, 0.68333342, 0.90389182,\n",
       "         0.85874995, 0.92527296, 0.89156498, 0.25012281]]),\n",
       " array([[ 861., 1000.]]),\n",
       " array([[  3., 861.]]),\n",
       " array([[3.]]),\n",
       " array([[0.87976131, 0.9297856 , 0.83549269, 0.90428252, 0.87623565,\n",
       "         0.78461872, 0.87272148, 0.83706342, 0.89178612, 0.94260169,\n",
       "         0.86621665, 0.78676416, 0.96718552, 0.93036856, 0.88533375,\n",
       "         0.87630723, 0.90611535, 0.90094671, 0.91896463, 0.89614277,\n",
       "         0.86091928, 0.8869204 , 0.90520281, 0.8706107 , 0.8712473 ,\n",
       "         0.88889902, 0.88828191, 0.87968163, 0.91316677, 1.        ,\n",
       "         0.86940006, 0.90262874, 0.8573486 , 0.78657226, 0.88417064,\n",
       "         0.94014566, 0.93205063, 0.99967825, 0.94994263, 0.9443178 ,\n",
       "         0.86809099, 0.8261856 , 0.89236361, 0.96419072, 0.87083902,\n",
       "         0.98087861, 0.87698113, 0.86885597, 0.95106234, 0.96118786,\n",
       "         0.88228546, 0.89628797, 0.85953501, 0.92595651]]),\n",
       " array([[0., 1., 0., ..., 0., 0., 1.],\n",
       "        [0., 1., 0., ..., 0., 0., 7.],\n",
       "        [0., 1., 0., ..., 0., 0., 1.],\n",
       "        ...,\n",
       "        [8., 4., 4., ..., 0., 2., 7.],\n",
       "        [1., 4., 4., ..., 0., 2., 7.],\n",
       "        [3., 4., 4., ..., 0., 2., 1.]]),\n",
       " array([[ 1.],\n",
       "        [53.],\n",
       "        [ 1.],\n",
       "        ...,\n",
       "        [47.],\n",
       "        [53.],\n",
       "        [ 2.]]),\n",
       " array([[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        ...,\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]]),\n",
       " array([[200000.]]),\n",
       " array([[0.75, 0.  ]])]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perx"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test lại tỷ lệ thắng "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "265\n"
     ]
    }
   ],
   "source": [
    "@njit()\n",
    "def p_bias_1(state,per):\n",
    "    actions = getValidActions(state)\n",
    "    # Check xem policy có yếu không \n",
    "    if check_weaker(per[12][0][0],np.mean(state)) == 1:\n",
    "      actions *= per[7][0]\n",
    "      action = np.argmax(actions)\n",
    "    else:\n",
    "      actions *= per[3][0]\n",
    "      action = np.argmax(actions)\n",
    "    return action,per\n",
    "win, bias = numba_main_2(p_bias_1, 1000,perx,1)\n",
    "print(win)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find the most important value of index in the state that when it appear the policy dont work well\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_most_importane_feature(perx):\n",
    "    import pandas as pd\n",
    "\n",
    "    df = pd.DataFrame(perx[8])\n",
    "    df['action'] = perx[9]\n",
    "    df['reward'] = perx[10]\n",
    "    for i in range(len(df)):\n",
    "        if df['reward'][i] == -1:\n",
    "            for j in range(i,len(df)):\n",
    "                if df['reward'][j] != -1:\n",
    "                    df['reward'][i] = df['reward'][j]\n",
    "                    break\n",
    "    df = df[df['reward'] != -1]\n",
    "\n",
    "    import pandas as pd\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "    # Load the state-action dataset\n",
    "\n",
    "    # Split the data into features (state properties) and target (outcome)\n",
    "    features = df.drop(\"reward\", axis=1)\n",
    "    target = df[\"reward\"]\n",
    "\n",
    "    # Train a Random Forest Classifier on the data\n",
    "    clf = RandomForestClassifier()\n",
    "    clf.fit(features, target)\n",
    "\n",
    "    # Get the feature importances\n",
    "    importances = clf.feature_importances_\n",
    "\n",
    "    # Find the property (x) of the state that is most important for the policy's performance\n",
    "    x = features.columns[importances.argmax()]\n",
    "    # Plot the top  feature importances \n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.title(\"Feature importances\")\n",
    "    plt.bar(range(features.shape[1]), importances[indices], color=\"r\", align=\"center\")\n",
    "    plt.xticks(range(features.shape[1]), features.columns[indices], rotation=90)\n",
    "    plt.xlim([-1, features.shape[1]])\n",
    "    plt.show()\n",
    "    most_imp_feature = None\n",
    "    lowest_percentage = 100\n",
    "    print('feature importances',x)\n",
    "    for i in df[x].unique():\n",
    "        current_percentage = df[df[x] == i]['reward'].value_counts()[1]/df[df[x] == i]['reward'].value_counts().sum()\n",
    "        if current_percentage < lowest_percentage:\n",
    "            most_imp_feature = i\n",
    "            lowest_percentage = current_percentage\n",
    "\n",
    "    print(\"The value of the most important feature with the lowest percentage of value 1 in reward is:\", most_imp_feature)#  all the below code in one function    \n",
    "    return most_imp_feature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0 +10\n",
    "d = 0 \n",
    "while 0<i:\n",
    "    i = i-1\n",
    "    d= d+1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ff2136a0fe6bc790f1b40d257e6b1bba23119827483ea2b7c12c8cc23c661a47"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
